{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# ***Libraries***","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport pyarabic.araby as ar\n\nimport re , string\n\nfrom tqdm import tqdm_notebook as tqdm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, accuracy_score, f1_score, confusion_matrix, precision_score , recall_score\nfrom transformers import AutoConfig, AutoModelForSequenceClassification, AutoTokenizer, BertTokenizer\nfrom transformers.data.processors import SingleSentenceClassificationProcessor\nfrom transformers import Trainer , TrainingArguments\nfrom transformers.trainer_utils import EvaluationStrategy\nfrom transformers.data.processors.utils import InputFeatures\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\nfrom sklearn.utils import resample\n\nfrom huggingface_hub import notebook_login","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-14T18:25:46.512898Z","iopub.execute_input":"2022-03-14T18:25:46.513151Z","iopub.status.idle":"2022-03-14T18:25:46.524155Z","shell.execute_reply.started":"2022-03-14T18:25:46.513118Z","shell.execute_reply":"2022-03-14T18:25:46.523540Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"\nnotebook_login()","metadata":{"execution":{"iopub.status.busy":"2022-03-14T18:25:29.759571Z","iopub.execute_input":"2022-03-14T18:25:29.760032Z","iopub.status.idle":"2022-03-14T18:25:29.849728Z","shell.execute_reply.started":"2022-03-14T18:25:29.759995Z","shell.execute_reply":"2022-03-14T18:25:29.848930Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"repo_name = \"Predict Arabic dialects\"","metadata":{"execution":{"iopub.status.busy":"2022-03-14T18:25:57.921327Z","iopub.execute_input":"2022-03-14T18:25:57.921622Z","iopub.status.idle":"2022-03-14T18:25:57.926128Z","shell.execute_reply.started":"2022-03-14T18:25:57.921587Z","shell.execute_reply":"2022-03-14T18:25:57.925429Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## Load and Explore data","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/aim-technologies-predict-the-dialectal-arabic/dialect_dataset.csv\")\n\ntrain_df = train.copy()","metadata":{"execution":{"iopub.status.busy":"2022-03-14T18:25:59.828695Z","iopub.execute_input":"2022-03-14T18:25:59.829248Z","iopub.status.idle":"2022-03-14T18:26:00.087354Z","shell.execute_reply.started":"2022-03-14T18:25:59.829208Z","shell.execute_reply":"2022-03-14T18:26:00.086627Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train.info()","metadata":{"execution":{"iopub.status.busy":"2022-03-14T18:26:00.088892Z","iopub.execute_input":"2022-03-14T18:26:00.089154Z","iopub.status.idle":"2022-03-14T18:26:00.159691Z","shell.execute_reply.started":"2022-03-14T18:26:00.089108Z","shell.execute_reply":"2022-03-14T18:26:00.158949Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Prepare data before fetching process\n\n\ntrain['id'] = train['id'].astype(str)\nID = train['id'].tolist()\nlen(ID)","metadata":{"execution":{"iopub.status.busy":"2022-03-14T18:26:00.160972Z","iopub.execute_input":"2022-03-14T18:26:00.161364Z","iopub.status.idle":"2022-03-14T18:26:00.644312Z","shell.execute_reply.started":"2022-03-14T18:26:00.161327Z","shell.execute_reply":"2022-03-14T18:26:00.643596Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## Data fetching","metadata":{}},{"cell_type":"code","source":"import requests\n\nURL = \"https://recruitment.aimtechnologies.co/ai-tasks\"\n\nheaders= {\n    \n    \"Accept\": \"application/json\",\n    \"Content-Type\": \"application/json\"\n}\n","metadata":{"execution":{"iopub.status.busy":"2022-03-14T18:26:00.646421Z","iopub.execute_input":"2022-03-14T18:26:00.646862Z","iopub.status.idle":"2022-03-14T18:26:00.651302Z","shell.execute_reply.started":"2022-03-14T18:26:00.646822Z","shell.execute_reply":"2022-03-14T18:26:00.650620Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"reslist = []\nstart = 0\nend = 1000\n\nfor i in range(0,len(ID),1000):\n    \n        \n    if end > len(ID):\n        \n        break \n    \n    lst =[]\n        \n    for x in ID[start:end]:\n                \n        lst.append(x)\n            \n    response = requests.post(URL, json = lst, headers= headers).json()\n    \n    reslist.append(response)\n\n \n                           \n    start = start+1000\n    \n    end = end + 1000  ","metadata":{"execution":{"iopub.status.busy":"2022-03-14T18:26:00.652613Z","iopub.execute_input":"2022-03-14T18:26:00.652902Z","iopub.status.idle":"2022-03-14T18:40:00.551145Z","shell.execute_reply.started":"2022-03-14T18:26:00.652865Z","shell.execute_reply":"2022-03-14T18:40:00.550401Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"reslist2 = []\nlst = []\nfor x in ID[458000:]:\n                \n    lst.append(x)\n            \nresponse1 = requests.post(URL, json = lst, headers= headers).json()\nreslist2.append(response1)","metadata":{"execution":{"iopub.status.busy":"2022-03-14T18:40:00.552414Z","iopub.execute_input":"2022-03-14T18:40:00.552675Z","iopub.status.idle":"2022-03-14T18:40:01.673286Z","shell.execute_reply.started":"2022-03-14T18:40:00.552626Z","shell.execute_reply":"2022-03-14T18:40:01.672585Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"text = reslist + reslist2","metadata":{"execution":{"iopub.status.busy":"2022-03-14T18:40:01.675605Z","iopub.execute_input":"2022-03-14T18:40:01.676156Z","iopub.status.idle":"2022-03-14T18:40:01.679958Z","shell.execute_reply.started":"2022-03-14T18:40:01.676119Z","shell.execute_reply":"2022-03-14T18:40:01.679225Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"## Save data as a dataframe","metadata":{}},{"cell_type":"code","source":"df = pd.DataFrame(text).stack().apply(pd.Series)","metadata":{"execution":{"iopub.status.busy":"2022-03-14T18:40:01.681321Z","iopub.execute_input":"2022-03-14T18:40:01.681907Z","iopub.status.idle":"2022-03-14T18:43:02.023891Z","shell.execute_reply.started":"2022-03-14T18:40:01.681874Z","shell.execute_reply":"2022-03-14T18:43:02.023104Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"df = df.reset_index()","metadata":{"execution":{"iopub.status.busy":"2022-03-14T18:43:02.026788Z","iopub.execute_input":"2022-03-14T18:43:02.027053Z","iopub.status.idle":"2022-03-14T18:43:02.065044Z","shell.execute_reply.started":"2022-03-14T18:43:02.027019Z","shell.execute_reply":"2022-03-14T18:43:02.064304Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"## Rename column after reseting index","metadata":{}},{"cell_type":"code","source":"df = df.rename(columns={0: 'text', 'level_1': 'id'})","metadata":{"execution":{"iopub.status.busy":"2022-03-14T18:43:02.068263Z","iopub.execute_input":"2022-03-14T18:43:02.068511Z","iopub.status.idle":"2022-03-14T18:43:02.132068Z","shell.execute_reply.started":"2022-03-14T18:43:02.068483Z","shell.execute_reply":"2022-03-14T18:43:02.131315Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"df = df.drop(['level_0'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-03-14T18:43:02.133482Z","iopub.execute_input":"2022-03-14T18:43:02.133766Z","iopub.status.idle":"2022-03-14T18:43:02.162851Z","shell.execute_reply.started":"2022-03-14T18:43:02.133730Z","shell.execute_reply":"2022-03-14T18:43:02.162092Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"## Merge data ","metadata":{}},{"cell_type":"code","source":"df = pd.merge(train, df, on=\"id\")","metadata":{"execution":{"iopub.status.busy":"2022-03-14T18:43:02.164372Z","iopub.execute_input":"2022-03-14T18:43:02.164631Z","iopub.status.idle":"2022-03-14T18:43:02.536688Z","shell.execute_reply.started":"2022-03-14T18:43:02.164597Z","shell.execute_reply":"2022-03-14T18:43:02.535951Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2022-03-14T18:43:02.538112Z","iopub.execute_input":"2022-03-14T18:43:02.538376Z","iopub.status.idle":"2022-03-14T18:43:02.555282Z","shell.execute_reply.started":"2022-03-14T18:43:02.538342Z","shell.execute_reply":"2022-03-14T18:43:02.553996Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"## Data Preprocessing","metadata":{}},{"cell_type":"code","source":"# check nulls \ndf.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-03-14T18:43:02.556478Z","iopub.execute_input":"2022-03-14T18:43:02.556821Z","iopub.status.idle":"2022-03-14T18:43:02.711210Z","shell.execute_reply.started":"2022-03-14T18:43:02.556783Z","shell.execute_reply":"2022-03-14T18:43:02.710485Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"df.duplicated().sum()","metadata":{"execution":{"iopub.status.busy":"2022-03-14T18:43:02.712523Z","iopub.execute_input":"2022-03-14T18:43:02.712783Z","iopub.status.idle":"2022-03-14T18:43:03.348778Z","shell.execute_reply.started":"2022-03-14T18:43:02.712749Z","shell.execute_reply":"2022-03-14T18:43:03.348080Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"df['dialect'].nunique()","metadata":{"execution":{"iopub.status.busy":"2022-03-14T18:43:03.350075Z","iopub.execute_input":"2022-03-14T18:43:03.350484Z","iopub.status.idle":"2022-03-14T18:43:03.382344Z","shell.execute_reply.started":"2022-03-14T18:43:03.350448Z","shell.execute_reply":"2022-03-14T18:43:03.381560Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"df['dialect'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-03-14T18:43:03.384016Z","iopub.execute_input":"2022-03-14T18:43:03.384265Z","iopub.status.idle":"2022-03-14T18:43:03.436087Z","shell.execute_reply.started":"2022-03-14T18:43:03.384232Z","shell.execute_reply":"2022-03-14T18:43:03.435213Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"#df = pd.get_dummies(data=df, columns=['dialect'])","metadata":{"execution":{"iopub.status.busy":"2022-03-14T18:43:03.437699Z","iopub.execute_input":"2022-03-14T18:43:03.437970Z","iopub.status.idle":"2022-03-14T18:43:03.445133Z","shell.execute_reply.started":"2022-03-14T18:43:03.437935Z","shell.execute_reply":"2022-03-14T18:43:03.444058Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"#df\n","metadata":{"execution":{"iopub.status.busy":"2022-03-14T18:43:03.446527Z","iopub.execute_input":"2022-03-14T18:43:03.446852Z","iopub.status.idle":"2022-03-14T18:43:03.453782Z","shell.execute_reply.started":"2022-03-14T18:43:03.446819Z","shell.execute_reply":"2022-03-14T18:43:03.452839Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# lowercase names of col\ndf.rename(columns=lambda x: x.strip().lower(), inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-14T18:43:03.454899Z","iopub.execute_input":"2022-03-14T18:43:03.455196Z","iopub.status.idle":"2022-03-14T18:43:03.463565Z","shell.execute_reply.started":"2022-03-14T18:43:03.455162Z","shell.execute_reply":"2022-03-14T18:43:03.462865Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2022-03-14T18:43:03.465104Z","iopub.execute_input":"2022-03-14T18:43:03.465360Z","iopub.status.idle":"2022-03-14T18:43:03.479846Z","shell.execute_reply.started":"2022-03-14T18:43:03.465327Z","shell.execute_reply":"2022-03-14T18:43:03.479057Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"null_values = ['unknown','missing','?','','NULL','NaN']","metadata":{"execution":{"iopub.status.busy":"2022-03-14T18:43:03.481297Z","iopub.execute_input":"2022-03-14T18:43:03.481559Z","iopub.status.idle":"2022-03-14T18:43:03.488289Z","shell.execute_reply.started":"2022-03-14T18:43:03.481526Z","shell.execute_reply":"2022-03-14T18:43:03.487566Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"df = df.replace(null_values, np.NaN)","metadata":{"execution":{"iopub.status.busy":"2022-03-14T18:43:03.490491Z","iopub.execute_input":"2022-03-14T18:43:03.490768Z","iopub.status.idle":"2022-03-14T18:43:04.188049Z","shell.execute_reply.started":"2022-03-14T18:43:03.490732Z","shell.execute_reply":"2022-03-14T18:43:04.187311Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-03-14T18:43:04.189483Z","iopub.execute_input":"2022-03-14T18:43:04.189767Z","iopub.status.idle":"2022-03-14T18:43:04.338595Z","shell.execute_reply.started":"2022-03-14T18:43:04.189731Z","shell.execute_reply":"2022-03-14T18:43:04.337789Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"## Cleaning data ( Punctuation , mentions , emotion .. etc )","metadata":{}},{"cell_type":"code","source":"df['text']= df['text'].map(lambda text: re.sub(r'[^\\u0600-\\u06ff\\u0750-\\u077f\\ufb50-\\ufbc1\\ufbd3-\\ufd3f\\ufd50-\\ufd8f\\ufd50-\\ufd8f\\ufe70-\\ufefc\\uFDF0-\\uFDFD]+', ' ', text).strip())","metadata":{"execution":{"iopub.status.busy":"2022-03-14T18:43:04.340239Z","iopub.execute_input":"2022-03-14T18:43:04.340712Z","iopub.status.idle":"2022-03-14T18:43:08.967101Z","shell.execute_reply.started":"2022-03-14T18:43:04.340673Z","shell.execute_reply":"2022-03-14T18:43:08.966361Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"df['text']","metadata":{"execution":{"iopub.status.busy":"2022-03-14T18:43:08.968244Z","iopub.execute_input":"2022-03-14T18:43:08.968492Z","iopub.status.idle":"2022-03-14T18:43:08.978980Z","shell.execute_reply.started":"2022-03-14T18:43:08.968459Z","shell.execute_reply":"2022-03-14T18:43:08.978214Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"df.to_csv('data.csv')  ","metadata":{"execution":{"iopub.status.busy":"2022-03-14T18:43:08.980337Z","iopub.execute_input":"2022-03-14T18:43:08.980957Z","iopub.status.idle":"2022-03-14T18:43:11.866105Z","shell.execute_reply.started":"2022-03-14T18:43:08.980918Z","shell.execute_reply":"2022-03-14T18:43:11.865324Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"#df = pd.read_csv('data.csv')","metadata":{"execution":{"iopub.status.busy":"2022-03-14T18:43:11.869656Z","iopub.execute_input":"2022-03-14T18:43:11.869981Z","iopub.status.idle":"2022-03-14T18:43:11.873120Z","shell.execute_reply.started":"2022-03-14T18:43:11.869949Z","shell.execute_reply":"2022-03-14T18:43:11.872331Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"#df['id'] = df['id'].astype(int)","metadata":{"execution":{"iopub.status.busy":"2022-03-14T18:43:11.874341Z","iopub.execute_input":"2022-03-14T18:43:11.874735Z","iopub.status.idle":"2022-03-14T18:43:11.883518Z","shell.execute_reply.started":"2022-03-14T18:43:11.874699Z","shell.execute_reply":"2022-03-14T18:43:11.882725Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"df_set = df.copy()","metadata":{"execution":{"iopub.status.busy":"2022-03-14T18:43:11.884834Z","iopub.execute_input":"2022-03-14T18:43:11.885086Z","iopub.status.idle":"2022-03-14T18:43:11.905264Z","shell.execute_reply.started":"2022-03-14T18:43:11.885055Z","shell.execute_reply":"2022-03-14T18:43:11.904668Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"df_set = df_set.drop(['id'], axis=1 )\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_set","metadata":{"execution":{"iopub.status.busy":"2022-03-14T18:45:34.464912Z","iopub.execute_input":"2022-03-14T18:45:34.465367Z","iopub.status.idle":"2022-03-14T18:45:34.486542Z","shell.execute_reply.started":"2022-03-14T18:45:34.465323Z","shell.execute_reply":"2022-03-14T18:45:34.485934Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"# Model Training","metadata":{}},{"cell_type":"markdown","source":"## Predict by Using Linear svm (Machine Learning)","metadata":{}},{"cell_type":"code","source":"# split training data to train_set and validation_set\n\ntrain_set, val_set = train_test_split(\n    df_set, test_size= .10, random_state= 42 \n)\n\nprint(\"Train set: \")\nprint(train_set['dialect'].value_counts())\nprint(\"---------------------------\")\nprint (\"val set: \")\nprint (val_set['dialect'].value_counts())","metadata":{"execution":{"iopub.status.busy":"2022-03-14T18:45:42.411441Z","iopub.execute_input":"2022-03-14T18:45:42.411982Z","iopub.status.idle":"2022-03-14T18:45:42.550475Z","shell.execute_reply.started":"2022-03-14T18:45:42.411942Z","shell.execute_reply":"2022-03-14T18:45:42.549734Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"x = train_set['text'].to_list()\ny = train_set['dialect'].to_list()\nx_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.0005, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-03-14T18:46:32.863371Z","iopub.execute_input":"2022-03-14T18:46:32.864036Z","iopub.status.idle":"2022-03-14T18:46:33.086765Z","shell.execute_reply.started":"2022-03-14T18:46:32.863997Z","shell.execute_reply":"2022-03-14T18:46:33.086026Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nvectorizer = TfidfVectorizer(ngram_range=(1,8),  analyzer='char' ,  max_df=0.999999999, min_df=1, sublinear_tf=True, use_idf=True, norm='l2' )\ntrain_vectors = vectorizer.fit_transform(x_train)\nval_vectors = vectorizer.transform(x_val)\nprint(\"Shape o# training data : \", train_vectors.shape, \"\\nShape of validation data : \", val_vectors.shape)","metadata":{"execution":{"iopub.status.busy":"2022-03-14T18:46:35.333423Z","iopub.execute_input":"2022-03-14T18:46:35.333979Z","iopub.status.idle":"2022-03-14T18:53:13.538196Z","shell.execute_reply.started":"2022-03-14T18:46:35.333940Z","shell.execute_reply":"2022-03-14T18:53:13.537391Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"from sklearn.svm import LinearSVC\n\nmodel_LR = LinearSVC(max_iter =500 ,class_weight= 'balanced', random_state=42);\n\nmodel_LR.fit(train_vectors, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-03-14T18:53:27.009830Z","iopub.execute_input":"2022-03-14T18:53:27.010374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def performance(model, y_true, vectors):\n    from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n    print(\"Predicting the sentiments...\")\n    y_pred = model.predict(vectors)  # y_pred_RF = model_RF.predict(val_vectors)\n    df = pd.DataFrame({'actual': y_true, 'predicted': y_pred})\n    print(\"\\nAnalysis after prediction : \\n\")\n    d = df['predicted'].value_counts(normalize=True) * 100  # series\n    print(d)\n    ## plot for analysis\n    \n    cm = confusion_matrix(y_true, y_pred)\n    crp = classification_report(y_true, y_pred,digits=3)\n    acc = accuracy_score(y_true, y_pred)\n    return (cm, crp, acc)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"perform = performance(model_LR, y_val, val_vectors)\nprint(\"Confusion Matrix :\\n\", perform[0])\nprint(\"classification report: \\n\", perform[1])\nprint(\"Accuracy score  = \", perform[2] * 100)\nprint(\"-\" * 100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_vectors = vectorizer.transform(val_set['dialect'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted = model_LR.predict(test_vectors)\n\nprint(\"Results : \\n\")\n\nresults = pd.DataFrame({'text' : val_set['text'], 'dialect' : predicted},\n                       columns = ['text', 'dialect'])\n\nresults['dialect'] \nresults.to_csv(\"outputs.csv\", sep= \",\", index = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"out = pd.read_csv('outputs.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"out.head(50)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Predict by Using Bert (Deep learning)","metadata":{}},{"cell_type":"code","source":"import torch\n# If there's a GPU available...\nif torch.cuda.is_available():    \n    # Tell PyTorch to use the GPU.  \n\n    device = torch.device(\"cuda\")\n    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n    print('We will use the GPU:', torch.cuda.get_device_name(0))\n    !nvidia-smi\n    \n# If not...\nelse:\n    print('No GPU available, using the CPU instead.')\n    device = torch.device(\"cpu\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# a class representing the dataset\nclass Dataset:\n    def __init__(\n        self,\n        name,\n        train,\n        test,\n        label_list,\n    ):\n        self.name = name\n        self.train = train\n        self.test = test\n        self.label_list = label_list","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class BERTModelDataset(Dataset):\n    def __init__(self, text, target, model_name, max_len, label_map):\n        super(BERTModelDataset).__init__()\n        self.text = text\n        self.target = target\n        self.tokenizer_name = model_name\n        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n        self.max_len = max_len\n        self.label_map = label_map\n  \n    def __len__(self):\n        return len(self.text)\n\n    def __getitem__(self,item):\n        text = str(self.text[item])\n        text = \" \".join(text.split())\n    \n        encoded_review = self.tokenizer.encode_plus(\n        text,\n        max_length= self.max_len,\n        add_special_tokens= True,\n        return_token_type_ids=False,\n        pad_to_max_length=True,\n        truncation='longest_first',\n        return_attention_mask=True,\n        return_tensors='pt'\n      )\n        input_ids = encoded_review['input_ids'].to(device)\n        attention_mask = encoded_review['attention_mask'].to(device)\n\n        return InputFeatures(input_ids=input_ids.flatten(), attention_mask=attention_mask.flatten(), label=self.label_map[self.target[item]])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# prepare for Training\n\nModel_Used = \"UBC-NLP/MARBERT\"\nTask_Name = \"classification\"\n\nMax_Len = 0 \nExtra_Len = 6\n\nlabel_list = list(train_set['dialect'].unique())\n\nprint(label_list)\n\nprint(train_set['dialect'].value_counts())\n\ndata_set = Dataset( \"AIMTech\", train_set, val_set, label_list )\n\nlabel_map = { v:index for index, v in enumerate(label_list) }\n\nprint(label_map)\n\ntrain_dataset = BERTModelDataset(train_set['dialect'].to_list(),\n                                 train_set['dialect'].to_list(),Model_Used,Max_Len,label_map)\n\nevaluation_dataset = BERTModelDataset(val_set['dialect'].to_list(),\n                                     val_set['dialect'].to_list(),Model_Used,Max_Len,label_map)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def model_init():\n    return AutoModelForSequenceClassification.from_pretrained(Model_Used, return_dict=True, num_labels=len(label_map))\n\ndef compute_metrics(p): #p should be of type EvalPrediction\n    preds = np.argmax(p.predictions, axis=1)\n    assert len(preds) == len(p.label_ids)\n    print(classification_report(p.label_ids,preds))\n    #print(confusion_matrix(p.label_ids,preds))\n\n    macro_f1_pos_neg = f1_score(p.label_ids,preds,average='macro',labels=[1,2])\n    macro_f1 = f1_score(p.label_ids,preds,average='macro')\n    macro_precision = precision_score(p.label_ids,preds,average='macro')\n    macro_recall = recall_score(p.label_ids,preds,average='macro')\n    acc = accuracy_score(p.label_ids,preds)\n    return {\n        'macro_f1' : macro_f1,\n        'macro_f1_pos_neg' : macro_f1_pos_neg,  \n        'macro_precision': macro_precision,\n        'macro_recall': macro_recall,\n        'accuracy': acc\n           }\n\ndef set_seed(seed):\n    \n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    np.random.seed(seed)\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_args = TrainingArguments(\"./train\")\ntraining_args.lr_scheduler_type = 'cosine'\ntraining_args.evaluate_during_training = True\ntraining_args.adam_epsilon =1e-8 \ntraining_args.learning_rate =  1.215e-05\ntraining_args.fp16 = True\n#1.215e-05 # best score 5-6-2021\ntraining_args.per_device_train_batch_size = 16 #64 #69\ntraining_args.per_device_eval_batch_size = 16 # 64 #69\ntraining_args.gradient_accumulation_steps = 2\ntraining_args.num_train_epochs= 2\ntraining_args.warmup_steps = 0 \ntraining_args.evaluation_strategy = EvaluationStrategy.EPOCH\ntraining_args.logging_steps = 200\ntraining_args.save_steps = 100000 #don't want to save any model, there is probably a better way to do this :)\ntraining_args.seed = 42 #42 #was 84 #42 #42 #123 # 666 #0 #42\ntraining_args.disable_tqdm = False\ntraining_args.output_dir=repo_name","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# prepare for Training\nlabel_list = list(train_set['dialect'].unique())\n\nprint(label_list)\nprint(train_set['dialect'].value_counts())\n\ndata_set = Dataset( \"AIMTech\", train_set, val_set, label_list )\n\nlabel_map = { v:index for index, v in enumerate(label_list) }\nprint(label_map)\n\ntrain_dataset = BERTModelDataset(train_set['text'].to_list(),\n                                 train_set['dialect'].to_list(),Model_Used,Max_Len,label_map)\n\nevaluation_dataset = BERTModelDataset(val_set['text'].to_list(),\n                                      eval_set['dialect'].to_list(),Model_Used,Max_Len,label_map)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntrainer = Trainer(\n    model = model_init(),\n    args = training_args,\n    train_dataset = train_dataset,\n    eval_dataset= evaluation_dataset,\n    compute_metrics=compute_metrics\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(Max_Len)\nprint(training_args.learning_rate)\n#print(train_data_file)\nprint(training_args.adam_epsilon)\nprint(training_args.warmup_steps)\n\ntrainer.train()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.push_to_hub()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}